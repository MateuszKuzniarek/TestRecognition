\documentclass{classrep}
\usepackage[utf8]{inputenc}
\usepackage{color}

\studycycle{Informatyka, studia dzienne, I st.}
\coursesemester{VI}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2018/2019}

\courseteacher{dr inż. Marcin Kacprowicz}
\coursegroup{Wtorek, 16:15}

\author{
  \studentinfo{Paweł Młynarczyk}{210278} \and
  \studentinfo{Mateusz Kuźniarek}{210245}
}

\title{Zadanie 1 - Ekstrakcja cech, miary podobieństwa, klasyfikacja.}

\begin{document}
\maketitle

\section{Cel}
Celem zadania było zaprojektowanie i implementacja narzędzia, pozwalającego na klasyfikację tekstów przy użyciu algorytmu KNN. Podczas realizacji ćwiczenia, należało zbadać wpływ parametrów takich, jak sposób ekstrakcji cech, czy użyta miara podobieństwa na skuteczność i szybkość procesu klasyfikacji.

\section{Wprowadzenie}
\subsection{Ekstrakcja cech}
W celu szybkiego i efektywnego porównywania tekstów przydatna okazuje się ich reprezentacja w postaci wektora liczb. Współrzędne takiego wektora odpowiadają poszczególnym cechom, opisującym reprezentowany tekst. Proces analizy tekstu i określenia wartości liczbowej dla danej jego własności nazywamy ekstrakcją cech. Wybór odpowiedniego sposobu ekstrakcji jest kluczowy dla efektywnego działania programu. W ramach zadania zaimplementowano 3 takie sposoby.


\subsubsection{TF (Term Frequency)}
Dla każdego słowa kluczowego obliczana jest jego częstotliwość przy pomocy wzoru: 
\begin{equation}
tf(t,d) =  \frac{f_{t,d}}{|d|}
\end{equation}
gdzie \(f_{t,d}\) jest liczbą wsytąpień słowa \(t\) w tekście \(d\), a \(|d|\) jest liczbą wszystkich słów w tym tekście. Wartości funkcji \(tf(t,d)\) dla każdego słowa kluczowego stanową współrzędne wektora, reprezentującego dany dokument.

\subsubsection{TF-IDF (term frequency–inverse document frequency)}
Ten sposób ekstrakcji cech wykorzystuje TF(Term Frequency) i wzbogaca je o informację na temat tego, jak często dane słowo znajduje się w dokementach innych niż analizowany. Wartość TF-IDF można uzyskać przy pomocy wzoru: 
\begin{equation}
tfidf(t,d,D) = tf(t,d) \cdot idf(t,D)
\end{equation}
gdzie \(tf(t,d)\), jest wartością TF obliczoną przy pomocy woru 1., a \(idf(t,D)\) wyraża się wzorem
\begin{equation}
idf(t,D) = log\frac{|D|}{n}
\end{equation}
gdzie \(|D|\) to liczba wszystkich tekstów w analizowanym zbiorze, a \(n\) to liczba tekstów, w których przynajmniej raz znajduje się słowo \(t\).

\subsubsection{Własna metoda ekstrakcji cech}
Trzecim wykorzystanym sposobem była własna metoda ekstrakcji wektora cech. Składała się ona z następujących własności:
\begin{itemize}
	\item Suma wartości TF dla grupy słów kluczowych
	\item Długość tekstu
	\item Średnia z występujących w tekście liczb
	\item Średnia długość słowa wśród 4 najdłuższych słów
\end{itemize}

\subsection{Algorytm KNN}
Do klasyfikacji tekstów wykorzystany został algorytm KNN(k-nearest neighbors). Pozwala on na przypisanie danej próbce klasy na podstawie tego, jak zaklsyfikowani są jej najbliżsi sąsiedzi. Bliskość dwóch próbek zdefiniowana jest za pomocą odpowiedniej metryki lub miary podobieństwa. 

W ramach zadania zaimplementowano następujące metryki: \newline
Metryka euklidesowa:
\begin{equation}
d(p,q) = \sqrt{\sum_{i=1}^{n} (p_{i} -q_{i})^{2}}
\end{equation}
Metryka uliczna:
\begin{equation}
d(p,q) = \sum_{i=1}^{n} |p_{i} -q_{i}|
\end{equation}
Metryka Czebyszewa:
\begin{equation}
d(p,q) = max_{i}(p_{i} -q_{i})
\end{equation}
gdzie \(n\) jest długością wektorów \(p = [p_{1}, p_{2}, ..., p_{n}]\) oraz \(q = [q_{1}, q_{2}, ..., q_{n}]\) są wektorami, między którymi liczona jest odległość. 

{\color{blue}
TO BE CONTINUED }

\section{Opis implementacji}

W celu realizacji zadania została napisana aplikacja okienkowa w języku Java. Warstwa prezentacji została z kolei przygotowana w technologii JavaFx\cite{JavaFX}.

Projekt podzielono na dwa główne pakiety, przechowujący klasy warstwy prezentacji pakiet \textit{gui}, oraz pakiet \textit{logic}, w którym jest zawarta cała logika aplikacji. Na pakiet \textit{logic} składają się liczne podpakiety, które wydzielają poszczególne funkcjonalności aplikacji jeszcze bardziej. Są to: pakiet \textit{classification}, którego klasy realizują zagadnienie klasyfikacji obiektów tekstowych; pakiet \textit{extractors}, który zawiera w sobie ekstraktory cech; pakiet \textit{features} zawierający w sobie klasy, reprezentujące cechy obiektów; pakiet \textit{metrics}, którego klasy realizują poszczególne metryki; oraz pakiet \textit{utils} zawierający w sobie wszystkie klasy wspomagające działanie programu, niezwiązane bezpośrednio z idęą działania sieci knn.

Opis poszczególnych klas w ramach pakietu:

\begin{itemize}
	\item gui
	\begin{itemize}
		\item MainApp.java - klasa uruchomieniowa aplikacji, jej celem jest jedynie skonfigurowanie oraz ustawienie nowej sceny JavaFX;
		\item FXMLController.java - klasa kontrolera JavaFX przypisana do pliku FXML definiująca sposób działania elementów interfejsu użytkownika;
	\end{itemize}
	\item logic.classification
	\begin{itemize}
		\item TextSample.java - klasa reprezentująca próbkę tekstu, będąca reprezentacją badanych artykułów, zawiera informacje o etykiecie, i słowach zawartych w artykule;
		\item ExtractedSample.java - klasa reprezentująca wyekstrahowaną próbkę tekstu, na którą składa się jedynie etykieta oraz wektor cech tej próbki;
		\item Normalizer.java - klasa zdolna normalizować cechy wyekstrahowanej próbki do przedziału [0,1], w oparciu o cechy zbioru obiektów(tu zbioru treningowego);
		\item KNNClasification.java - reprezentacja sieci knn, do najważniejszych metod tej klasy należą metoda \textit{train()}, która bazując na zbiorze testowym, tworzy strukturę sieci, oraz metoda \textit{classify()} dokonująca klasyfikacji obiektów zbioru testowego w oparciu o utworzoną wcześniej strukturę;
	\end{itemize}
	\item logic.extraction
	\begin{itemize}
		\item FeatureExtractor.java - klasa abstrakcyjna ekstraktora cech;
		\item TFExtractor.java - klasa ekstraktora cechy term frequency generująca cechy w oparciu o częstotliwość występowania słów kluczowych;
		\item TFIDFExtractor.java - klasa ekstraktora cech term frequency inverse document frequency, która ekstrahuje cechy w oparciu o częstotliwość wystąpienia słów kluczowych oraz ich unikalności w stosunku do badanego obiektu;
		\item CustomExtractor.java - klasa autorskiego ekstraktora cech, który działa w oparciu o długość słów???????????, średnią długość najdłuższych słów, oraz średnią arytmetyczną wszystkich liczb o ile wystąpiły w tekście;
	\end{itemize}
	\item logic.features
	\begin{itemize}
		\item todo
	\end{itemize}
	\item logic.metrics
	\begin{itemize}
		\item todo
	\end{itemize}
	\item logic.utils
	\begin{itemize}
		\item todo
	\end{itemize}
\end{itemize}

{\color{blue}
Należy tu zamieścić krótki i zwięzły opis zaprojektowanych klas oraz powiązań
między nimi. Powinien się tu również znaleźć diagram UML  (diagram klas)
prezentujący najistotniejsze elementy stworzonej aplikacji. Należy także
podać, w jakim języku programowania została stworzona aplikacja. }

\section{Materiały i metody}
{\color{blue}
W tym miejscu należy opisać, jak przeprowadzone zostały wszystkie badania,
których wyniki i dyskusja zamieszczane są w dalszych sekcjach. Opis ten
powinien być na tyle dokładny, aby osoba czytająca go potrafiła wszystkie
przeprowadzone badania samodzielnie powtórzyć w celu zweryfikowania ich
poprawności (a zatem m.in. należy zamieścić tu opis architektury sieci,
wartości współczynników użytych w kolejnych eksperymentach, sposób
inicjalizacji wag, metodę uczenia itp. oraz informacje o danych, na których
prowadzone były badania). Przy opisie należy odwoływać się i stosować do
opisanych w sekcji drugiej wzorów i oznaczeń, a także w jasny sposób opisać
cel konkretnego testu. Najlepiej byłoby wyraźnie wyszczególnić (ponumerować)
poszczególne eksperymenty tak, aby łatwo było się do nich odwoływać dalej.}

\section{Wyniki}
{\color{blue}
W tej sekcji należy zaprezentować, dla każdego przeprowadzonego eksperymentu,
kompletny zestaw wyników w postaci tabel, wykresów itp. Powinny być one tak
ponazywane, aby było wiadomo, do czego się odnoszą. Wszystkie tabele i wykresy
należy oczywiście opisać (opisać co jest na osiach, w kolumnach itd.) stosując
się do przyjętych wcześniej oznaczeń. Nie należy tu komentować i interpretować
wyników, gdyż miejsce na to jest w kolejnej sekcji. Tu również dobrze jest
wprowadzić oznaczenia (tabel, wykresów) aby móc się do nich odwoływać
poniżej.}

\section{Dyskusja}
{\color{blue}
Sekcja ta powinna zawierać dokładną interpretację uzyskanych wyników
eksperymentów wraz ze szczegółowymi wnioskami z nich płynącymi. Najcenniejsze
są, rzecz jasna, wnioski o charakterze uniwersalnym, które mogą być istotne
przy innych, podobnych zadaniach. Należy również omówić i wyjaśnić wszystkie
napotakane problemy (jeśli takie były). Każdy wniosek powinien mieć poparcie
we wcześniej przeprowadzonych eksperymentach (odwołania do konkretnych
wyników). Jest to jedna z najważniejszych sekcji tego sprawozdania, gdyż
prezentuje poziom zrozumienia badanego problemu.}
\section{Wnioski}
{\color{blue}W tej, przedostatniej, sekcji należy zamieścić podsumowanie
najważniejszych wniosków z sekcji poprzedniej. Najlepiej jest je po prostu
wypunktować. Znów, tak jak poprzednio, najistotniejsze są wnioski o
charakterze uniwersalnym.}


\begin{thebibliography}{0}

\bibitem{JavaFX} 
https://docs.oracle.com/javase/8/javafx/api/toc.htm

\end{thebibliography}
{\color{blue} 
Na końcu należy obowiązkowo podać cytowaną w sprawozdaniu
literaturę, z której grupa korzystała w trakcie prac nad zadaniem (przykład na
końcu szablonu)}
\end{document}
